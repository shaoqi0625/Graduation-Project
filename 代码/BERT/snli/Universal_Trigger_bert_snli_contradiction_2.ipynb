{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1843b45d-1914-4a19-a826-a7bf0c5b5d56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at PreTrainedModelBert/pytorch_model.bin and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import random\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "import warnings\n",
    "import csv\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "global extracted_grads\n",
    "\n",
    "extracted_grads = []\n",
    "position = 1  # concatenation position\n",
    "# the concatenation position of the BERT model is after the [CLS] token\n",
    "# Random Concatenation Mode\n",
    "# position = random.randint(1,500)\n",
    "\n",
    "BERT_path = 'PreTrainedModelBert'  # path to bert model\n",
    "tokenize = BertTokenizer.from_pretrained(os.path.join(BERT_path, 'vocab.txt'))\n",
    "model_config = BertConfig.from_pretrained(os.path.join(BERT_path, 'config.json'))\n",
    "Model = BertForSequenceClassification.from_pretrained(os.path.join(BERT_path, 'pytorch_model.bin'), config=model_config)\n",
    "\n",
    "# Load model related information\n",
    "\n",
    "# Print the number of Total Parameters\n",
    "# total = [param.nelement() for param in Model.parameters()]\n",
    "# print(f'total parameters:{format(sum(total))}\\n each layer parameters{total} ')\n",
    "\n",
    "'''\n",
    "SNLI Data\n",
    "'''\n",
    "\n",
    "\n",
    "### Load data\n",
    "\n",
    "def extract_text(s):\n",
    "    # 移除括号\n",
    "    s = re.sub('\\\\(', '', s)\n",
    "    s = re.sub('\\\\)', '', s)\n",
    "    # 使用一个空格替换两个以上连续空格\n",
    "    s = re.sub('\\\\s{2,}', ' ', s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def read_snli_binary_data(data_dir, is_train):\n",
    "    \"\"\"读取SNLI二分类数据集\"\"\"\n",
    "    label_set = {'entailment': 0, 'contradiction': 1}\n",
    "    file_name = os.path.join(data_dir, 'snli_1.0_train.txt' if is_train else 'snli_1.0_test.txt')\n",
    "    with open(file_name, 'r') as f:\n",
    "        rows = [row.split('\\t') for row in f.readlines()[1:]]\n",
    "\n",
    "    # 过滤数据并重新标记标签\n",
    "    data = [(extract_text(row[1]) + ' ' + extract_text(row[2]), label_set[row[0]])\n",
    "            for row in rows if row[0] in label_set]\n",
    "\n",
    "    # 分离文本和标签\n",
    "    texts, labels = zip(*data)\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def read_snli_binary_test_data(data_dir, is_train):\n",
    "    \"\"\"读取SNLI二分类数据集\"\"\"\n",
    "    # label_set = {'entailment': 0, 'contradiction': 1}\n",
    "    # label_set = {'entailment': 0}\n",
    "    label_set = {'contradiction': 1}\n",
    "    file_name = os.path.join(data_dir, 'snli_1.0_train.txt' if is_train else 'snli_1.0_test.txt')\n",
    "    with open(file_name, 'r') as f:\n",
    "        rows = [row.split('\\t') for row in f.readlines()[1:]]\n",
    "\n",
    "    # 过滤数据并重新标记标签\n",
    "    data = [(extract_text(row[1]) + ' ' + extract_text(row[2]), label_set[row[0]])\n",
    "            for row in rows if row[0] in label_set]\n",
    "\n",
    "    # 分离文本和标签\n",
    "    texts, labels = zip(*data)\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def load_snli_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Constructs a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "def load_snli_data(train_batch_size, test_batch_iter, num_steps=500):\n",
    "    train_data = read_snli_binary_data('snli_1.0', is_train=True)\n",
    "    test_data = read_snli_binary_test_data('snli_1.0', is_train=False)\n",
    "    train_encoding = tokenize(train_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    train_iter = load_snli_array(\n",
    "        (train_encoding['input_ids'], train_encoding['token_type_ids'], torch.tensor(train_data[1])),\n",
    "        train_batch_size)\n",
    "    test_iter = load_snli_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        test_batch_iter,\n",
    "        is_train=False)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "\n",
    "### Train\n",
    "\n",
    "def train(net, train_iter, lr, num_epochs, device):\n",
    "    print('---------------------------start---------------------')\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "    net = net.to(device[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        print(f' epoch {epoch + 1}')\n",
    "        train_losses = []\n",
    "        train_accs = []\n",
    "        train_length = 0\n",
    "        for batch in tqdm(train_iter):\n",
    "            a, b, y = batch\n",
    "            a = a.to(device[0])\n",
    "            b = b.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            outputs = net(input_ids=a, token_type_ids=b, labels=y)\n",
    "            logits = outputs.logits\n",
    "            l = outputs.loss\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            acc = (logits.argmax(dim=-1) == y).float().mean()\n",
    "            train_losses.append(l)\n",
    "            train_accs.append(acc)\n",
    "            train_length += len(y)\n",
    "        print(\"Learning rate for epoch %d：%f\" % (epoch + 1, optimizer.param_groups[0]['lr']))\n",
    "        train_loss = sum(train_losses) / len(train_iter)\n",
    "        train_acc = sum(train_accs) / len(train_iter)\n",
    "        print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}   acc = {train_acc:.5f}\")\n",
    "    print('Training process has finished.')\n",
    "    print('the loss of model {:.3f}'.format(train_loss))\n",
    "\n",
    "\n",
    "def evaluate_no(net, test_iter):\n",
    "    net = net.to(device[0])\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            a, b, y = batch\n",
    "            a = a.to(device[0])\n",
    "            b = b.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            outputs = net(input_ids=a, token_type_ids=b, labels=y)\n",
    "            acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "            valid_accs.append(acc)\n",
    "    valid_acc = sum(valid_accs) / len(test_iter)\n",
    "    return valid_acc\n",
    "\n",
    "\n",
    "### Trigger Token\n",
    "\n",
    "def init_trigger_tokens(trigger, num_trigger_tokens):\n",
    "    # Initialize trigger tokens, we use 'the' as initial trigger token\n",
    "    trigger_token_ids = [1996] * num_trigger_tokens  # 1996 means 'the'\n",
    "    trigger_token_tensor = torch.tensor(trigger_token_ids)\n",
    "    return trigger_token_tensor\n",
    "\n",
    "\n",
    "def evaluate(net, test_iter, trigger_token_tensor):\n",
    "    # evaluate the accuracy of the model after concatenating the initial trigger token\n",
    "    net = net.to(device[0])\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    n = torch.tensor([0] * len(trigger_token_tensor))\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    n = n.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            a, b, y = batch\n",
    "            a = torch.cat((a[:, :position], m.repeat_interleave(a.shape[0], dim=0), a[:, position:]), dim=1)\n",
    "            b = torch.cat((b[:, :position], n.repeat_interleave(b.shape[0], dim=0), b[:, position:]), dim=1)\n",
    "            a = a.to(device[0])\n",
    "            b = b.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            outputs = net(input_ids=a, token_type_ids=b, labels=y)\n",
    "            acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "            valid_accs.append(acc)\n",
    "    valid_acc = sum(valid_accs) / len(test_iter)\n",
    "    return valid_acc\n",
    "\n",
    "\n",
    "def extract_grad_hook(net, grad_in, grad_out):  # store the gradient in extracted_grads\n",
    "    extracted_grads.append(grad_out[0].mean(dim=0))\n",
    "\n",
    "\n",
    "def add_hook(net):\n",
    "    for module in net.modules():\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            hook = module.register_backward_hook(extract_grad_hook)\n",
    "            break\n",
    "    return hook\n",
    "\n",
    "\n",
    "def get_gradient(net, test_iter, trigger_token_tensor):  # Calculate the loss to get the gradient\n",
    "    net = net.to(device[0])\n",
    "    net.train()\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    n = torch.tensor([0] * len(trigger_token_tensor))\n",
    "    n = n.unsqueeze(0)\n",
    "    optimizer = torch.optim.AdamW(net.parameters())\n",
    "    for batch in tqdm(test_iter):\n",
    "        a, b, y = batch\n",
    "        a = torch.cat((a[:, :position], m.repeat_interleave(a.shape[0], dim=0), a[:, position:]), dim=1)\n",
    "        b = torch.cat((b[:, :position], n.repeat_interleave(b.shape[0], dim=0), b[:, position:]), dim=1)\n",
    "        a = a.to(device[0])\n",
    "        b = b.to(device[0])\n",
    "        y = y.to(device[0])\n",
    "        outputs = net(input_ids=a, token_type_ids=b, labels=y)\n",
    "        l = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "\n",
    "\n",
    "def process_gradient(length, num_trigger_tokens):  # Process the gradient to get the average gradient\n",
    "    extracted_grads_copy = extracted_grads\n",
    "    extracted_grads_copy[0] = extracted_grads_copy[0]\n",
    "    temp = extracted_grads_copy[0]\n",
    "    temp = temp.unsqueeze(0)\n",
    "    for i in range(1, length - 1):\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i]\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i].unsqueeze(0)\n",
    "        temp = torch.cat((temp, extracted_grads_copy[i]), dim=0)\n",
    "    average_grad = temp.mean(dim=0)[position:position + num_trigger_tokens]\n",
    "    return average_grad\n",
    "\n",
    "\n",
    "def hotflip_attack(averaged_grad, embedding_matrix,\n",
    "                   num_candidates=1, increase_loss=False):\n",
    "    averaged_grad = averaged_grad.cpu()\n",
    "    embedding_matrix = embedding_matrix.cpu()\n",
    "    averaged_grad = averaged_grad.unsqueeze(0)\n",
    "    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n",
    "                                                 (averaged_grad, embedding_matrix))\n",
    "    if not increase_loss:\n",
    "        gradient_dot_embedding_matrix *= -1\n",
    "        # lower versus increase the class probability.\n",
    "    if num_candidates > 1:  # get top k options\n",
    "        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n",
    "        return best_k_ids.detach().cpu().numpy()[0]  # Return candidates\n",
    "    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n",
    "    return best_at_each_step[0].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def collection_attack(net, test_iter, num_candidates, num_epoch, trigger='the',  # Summarize each function\n",
    "                      num_trigger_tokens=3):\n",
    "    trigger_token_tensor = init_trigger_tokens(trigger, num_trigger_tokens)\n",
    "    print(f'Concatenation location:{position}')\n",
    "    valid_acc = evaluate(net, test_iter, trigger_token_tensor)\n",
    "    print(f'Initial trigger tokens state：the accuracy {valid_acc:.5f}')\n",
    "    embedding_weight = get_embedding_weight(net)\n",
    "    for i in range(num_epoch):\n",
    "        extracted_grads.clear()\n",
    "        hook = add_hook(net)\n",
    "        get_gradient(net, test_iter, trigger_token_tensor)\n",
    "        hook.remove()\n",
    "        average_grad = process_gradient(len(test_iter), num_trigger_tokens)\n",
    "        hot_token = hotflip_attack(average_grad, embedding_weight, num_candidates, increase_loss=True)\n",
    "        hot_token_tensor = torch.from_numpy(hot_token)\n",
    "        trigger_token_tensor, valid_acc = select_best_candid(net, test_iter, hot_token_tensor, trigger_token_tensor,\n",
    "                                                             valid_acc)\n",
    "        print(f'after {i + 1} rounds of attacking\\ntriggers: {trigger_token_tensor} \\nthe accuracy :{valid_acc:.5f} ')\n",
    "    return trigger_token_tensor, valid_acc  # Return the final trigger tokens (trigger length) and the accuracy after the attack\n",
    "\n",
    "\n",
    "def get_embedding_weight(net):\n",
    "    for module in net.modules():\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            weight = module.weight\n",
    "            break\n",
    "    return weight\n",
    "\n",
    "\n",
    "def select_best_candid(net, test_iter, candid_trigger, trigger_token, valid_acc):\n",
    "    # Concatenate each candidate to each input to determine the final trigger token\n",
    "    n = torch.tensor([0] * len(trigger_token))\n",
    "    n = n.unsqueeze(0)\n",
    "    trigger_token = trigger_token.unsqueeze(0)\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    for i in range(candid_trigger.shape[0]):\n",
    "        trigger_token_temp = deepcopy(trigger_token)\n",
    "        for j in range(candid_trigger.shape[1]):\n",
    "            trigger_token_temp[0, i] = candid_trigger[i, j]\n",
    "            valid_accs = []\n",
    "            for batch in tqdm(test_iter):\n",
    "                a, b, y = batch\n",
    "                a = torch.cat((a[:, :position], trigger_token_temp.repeat_interleave(a.shape[0], dim=0),\n",
    "                               a[:, position:]), dim=1)\n",
    "                b = torch.cat((b[:, :position], n.repeat_interleave(b.shape[0], dim=0),\n",
    "                               b[:, position:]), dim=1)\n",
    "                a = a.to(device[0])\n",
    "                b = b.to(device[0])\n",
    "                y = y.to(device[0])\n",
    "                outputs = net(input_ids=a, token_type_ids=b, labels=y)\n",
    "                acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "                valid_accs.append(acc)\n",
    "            temp = sum(valid_accs) / len(test_iter)\n",
    "            if temp < valid_acc:\n",
    "                valid_acc = temp\n",
    "                trigger_token[0, i] = candid_trigger[i, j]\n",
    "    return trigger_token[0], valid_acc  # Return the final trigger token and the accuracy after the attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5312b7c-1096-43d5-8feb-96da1939895b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data finished\n",
      "\n",
      "18331\n",
      "1079\n"
     ]
    }
   ],
   "source": [
    "# train_iter, test_iter = load_imdb_data(10)\n",
    "# train_iter, test_iter = load_sst_data(10)\n",
    "train_iter, test_iter = load_snli_data(20, 3)\n",
    "# Data preprocessing and loading\n",
    "print(\"reading data finished\\n\")\n",
    "print(len(train_iter))\n",
    "print(len(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439ae920-a371-4fff-8b0c-36fbd147bba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------start---------------------\n",
      " epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18331 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "100%|██████████| 18331/18331 [18:05<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for epoch 1：0.000005\n",
      "[ Train | 001/003 ] loss = 0.18846   acc = 0.92234\n",
      " epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18331/18331 [17:58<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for epoch 2：0.000005\n",
      "[ Train | 002/003 ] loss = 0.10166   acc = 0.96271\n",
      " epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18331/18331 [18:06<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for epoch 3：0.000005\n",
      "[ Train | 003/003 ] loss = 0.06908   acc = 0.97572\n",
      "Training process has finished.\n",
      "the loss of model 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1123/1123 [00:07<00:00, 157.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9599, device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_all_gpus():\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "               for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "device = try_all_gpus()\n",
    "# device = [torch.device('cpu')]\n",
    "train(Model, train_iter, 5e-6, 3, device)  # base BERT\n",
    "\n",
    "# train(Model, train_iter, 5e-5, 3, device) # else BERT\n",
    "# The accuracy of the model on the test set when no trigger token is concatenated\n",
    "\n",
    "evaluate_no(Model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c57ef9a-ca86-4617-a00a-5c0424d975d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(Model, 'Bert_snli.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c3354a5-8d6c-4745-a86f-b625826b8a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:06<00:00, 154.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9725, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('Bert_snli.bin')\n",
    "evaluate_no(model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fdf8fc6-20ab-4d59-a0ba-d076cb541930",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation location:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:06<00:00, 154.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trigger tokens state：the accuracy 0.96756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.04it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 123.95it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 123.58it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 122.52it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.56it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.97it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 122.82it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.98it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 122.52it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 122.56it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 122.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1 rounds of attacking\n",
      "triggers: tensor([19089, 22833]) \n",
      "the accuracy :0.95891 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.06it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.35it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.45it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.34it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 119.97it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.85it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.37it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.20it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.18it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.05it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2 rounds of attacking\n",
      "triggers: tensor([27056, 18545]) \n",
      "the accuracy :0.95428 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [01:00<00:00, 17.97it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.26it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.32it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.19it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.42it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.63it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.47it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.47it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.58it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.67it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.02it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.79it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.43it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.76it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.60it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 122.13it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.12it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.51it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.00it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.34it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 4 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.05it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.07it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.27it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.76it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.14it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.54it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.63it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.58it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 116.94it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.44it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 5 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.00it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.79it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.22it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.54it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.23it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.70it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.03it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.70it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.62it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.88it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 6 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.07it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.53it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.38it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.84it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.24it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.42it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.77it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.15it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.54it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.48it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 7 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.09it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 119.95it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.21it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.65it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.60it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.39it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.59it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 119.91it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.57it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.13it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 8 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 18.03it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.42it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 121.49it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.71it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.58it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.02it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.79it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.85it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.05it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.20it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 115.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 9 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:59<00:00, 17.99it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.39it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.05it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 117.28it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.54it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 118.49it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.56it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.24it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.27it/s]\n",
      "100%|██████████| 1079/1079 [00:08<00:00, 120.10it/s]\n",
      "100%|██████████| 1079/1079 [00:09<00:00, 119.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 rounds of attacking\n",
      "triggers: tensor([26940, 18545]) \n",
      "the accuracy :0.94810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([26940, 18545]), tensor(0.9481, device='cuda:0'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_attack(model, test_iter, 5, 10, trigger='the', num_trigger_tokens=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
