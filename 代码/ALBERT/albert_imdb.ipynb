{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c28c5b1-3ab8-4c91-9095-ce0479f0f119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import random\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "\n",
    "\n",
    "\n",
    "global extracted_grads\n",
    "\n",
    "extracted_grads = []\n",
    "position = 1  # concatenation position\n",
    "# the concatenation position of the BERT model is after the [CLS] token\n",
    "# Random Concatenation Mode\n",
    "# position = random.randint(1,500)\n",
    "\n",
    "tokenize = AlbertTokenizer.from_pretrained(\"/root/albert\")\n",
    "Model = AlbertModel.from_pretrained(\"/root/albert\")\n",
    "\n",
    "\n",
    "# Load model related information\n",
    "\n",
    "# Print the number of Total Parameters\n",
    "# total = [param.nelement() for param in Model.parameters()]\n",
    "# print(f'total parameters:{format(sum(total))}\\n each layer parameters{total} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f6cae4-fa5b-41db-81e4-edf9f7bb4aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "\n",
    "def read_data(data_dir, is_train):\n",
    "    data, labels = [], []\n",
    "    for label in ('neg', 'pos'):\n",
    "        data_path = os.path.join(data_dir, 'train' if is_train else 'test', label)\n",
    "        for file in os.listdir(data_path):\n",
    "            with open(os.path.join(data_path, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', ' ')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def read_test_data_pos(data_dir, is_train):\n",
    "    data, labels = [], []\n",
    "    label = 'pos'  # choose a label to attack\n",
    "    data_path = os.path.join(data_dir, 'train' if is_train else 'test', label)\n",
    "    for file in os.listdir(data_path):\n",
    "        with open(os.path.join(data_path, file), 'rb') as f:\n",
    "            review = f.read().decode('utf-8').replace('\\n', ' ')\n",
    "            data.append(review)\n",
    "            labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "def read_test_data_neg(data_dir, is_train):\n",
    "    data, labels = [], []\n",
    "    label = 'neg'  # choose a label to attack\n",
    "    data_path = os.path.join(data_dir, 'train' if is_train else 'test', label)\n",
    "    for file in os.listdir(data_path):\n",
    "        with open(os.path.join(data_path, file), 'rb') as f:\n",
    "            review = f.read().decode('utf-8').replace('\\n', ' ')\n",
    "            data.append(review)\n",
    "            labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Constructs a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "def try_all_gpus():\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "               for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "\n",
    "def load_imdb_data_pos(batch_size, num_steps=500):\n",
    "    data_dir = 'aclImdb'  # Path to download dataset\n",
    "    train_data = read_data(data_dir, True)\n",
    "    test_data = read_test_data_pos(data_dir, False)\n",
    "    train_encoding = tokenize(train_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    train_iter = load_array(\n",
    "        (train_encoding['input_ids'], train_encoding['token_type_ids'], torch.tensor(train_data[1])),\n",
    "        batch_size)\n",
    "    test_iter = load_array((test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "                           batch_size,\n",
    "                           is_train=False)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "def load_imdb_data_neg(batch_size, num_steps=500):\n",
    "    data_dir = 'aclImdb'  # Path to download dataset\n",
    "    train_data = read_data(data_dir, True)\n",
    "    test_data = read_test_data_neg(data_dir, False)\n",
    "    train_encoding = tokenize(train_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    train_iter = load_array(\n",
    "        (train_encoding['input_ids'], train_encoding['token_type_ids'], torch.tensor(train_data[1])),\n",
    "        batch_size)\n",
    "    test_iter = load_array((test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "                           batch_size,\n",
    "                           is_train=False)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "\n",
    "train_iter, test_iter_pos = load_imdb_data_pos(10)\n",
    "train_iter, test_iter_neg = load_imdb_data_neg(10)\n",
    "# Data preprocessing and loading\n",
    "print(\"reading data finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37527886-e29d-40df-adf5-e0eec56ffdfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Batch 100/2500, Loss: 0.7082\n",
      "Epoch 1/3, Batch 200/2500, Loss: 0.6946\n",
      "Epoch 1/3, Batch 300/2500, Loss: 0.6867\n",
      "Epoch 1/3, Batch 400/2500, Loss: 0.6794\n",
      "Epoch 1/3, Batch 500/2500, Loss: 0.6744\n",
      "Epoch 1/3, Batch 600/2500, Loss: 0.6690\n",
      "Epoch 1/3, Batch 700/2500, Loss: 0.6620\n",
      "Epoch 1/3, Batch 800/2500, Loss: 0.6603\n",
      "Epoch 1/3, Batch 900/2500, Loss: 0.6557\n",
      "Epoch 1/3, Batch 1000/2500, Loss: 0.6539\n",
      "Epoch 1/3, Batch 1100/2500, Loss: 0.6496\n",
      "Epoch 1/3, Batch 1200/2500, Loss: 0.6472\n",
      "Epoch 1/3, Batch 1300/2500, Loss: 0.6429\n",
      "Epoch 1/3, Batch 1400/2500, Loss: 0.6407\n",
      "Epoch 1/3, Batch 1500/2500, Loss: 0.6398\n",
      "Epoch 1/3, Batch 1600/2500, Loss: 0.6391\n",
      "Epoch 1/3, Batch 1700/2500, Loss: 0.6381\n",
      "Epoch 1/3, Batch 1800/2500, Loss: 0.6367\n",
      "Epoch 1/3, Batch 1900/2500, Loss: 0.6356\n",
      "Epoch 1/3, Batch 2000/2500, Loss: 0.6351\n",
      "Epoch 1/3, Batch 2100/2500, Loss: 0.6339\n",
      "Epoch 1/3, Batch 2200/2500, Loss: 0.6331\n",
      "Epoch 1/3, Batch 2300/2500, Loss: 0.6331\n",
      "Epoch 1/3, Batch 2400/2500, Loss: 0.6325\n",
      "Epoch 1/3, Batch 2500/2500, Loss: 0.6318\n",
      "Epoch 2/3, Batch 100/2500, Loss: 0.6098\n",
      "Epoch 2/3, Batch 200/2500, Loss: 0.6103\n",
      "Epoch 2/3, Batch 300/2500, Loss: 0.6091\n",
      "Epoch 2/3, Batch 400/2500, Loss: 0.6069\n",
      "Epoch 2/3, Batch 500/2500, Loss: 0.6079\n",
      "Epoch 2/3, Batch 600/2500, Loss: 0.6046\n",
      "Epoch 2/3, Batch 700/2500, Loss: 0.6062\n",
      "Epoch 2/3, Batch 800/2500, Loss: 0.6047\n",
      "Epoch 2/3, Batch 900/2500, Loss: 0.6047\n",
      "Epoch 2/3, Batch 1000/2500, Loss: 0.6025\n",
      "Epoch 2/3, Batch 1100/2500, Loss: 0.5988\n",
      "Epoch 2/3, Batch 1200/2500, Loss: 0.5980\n",
      "Epoch 2/3, Batch 1300/2500, Loss: 0.5949\n",
      "Epoch 2/3, Batch 1400/2500, Loss: 0.5914\n",
      "Epoch 2/3, Batch 1500/2500, Loss: 0.5738\n",
      "Epoch 2/3, Batch 1600/2500, Loss: 0.5569\n",
      "Epoch 2/3, Batch 1700/2500, Loss: 0.5403\n",
      "Epoch 2/3, Batch 1800/2500, Loss: 0.5225\n",
      "Epoch 2/3, Batch 1900/2500, Loss: 0.5049\n",
      "Epoch 2/3, Batch 2000/2500, Loss: 0.4889\n",
      "Epoch 2/3, Batch 2100/2500, Loss: 0.4745\n",
      "Epoch 2/3, Batch 2200/2500, Loss: 0.4622\n",
      "Epoch 2/3, Batch 2300/2500, Loss: 0.4494\n",
      "Epoch 2/3, Batch 2400/2500, Loss: 0.4372\n",
      "Epoch 2/3, Batch 2500/2500, Loss: 0.4271\n",
      "Epoch 3/3, Batch 100/2500, Loss: 0.1424\n",
      "Epoch 3/3, Batch 200/2500, Loss: 0.1502\n",
      "Epoch 3/3, Batch 300/2500, Loss: 0.1479\n",
      "Epoch 3/3, Batch 400/2500, Loss: 0.1499\n",
      "Epoch 3/3, Batch 500/2500, Loss: 0.1508\n",
      "Epoch 3/3, Batch 600/2500, Loss: 0.1460\n",
      "Epoch 3/3, Batch 700/2500, Loss: 0.1460\n",
      "Epoch 3/3, Batch 800/2500, Loss: 0.1480\n",
      "Epoch 3/3, Batch 900/2500, Loss: 0.1481\n",
      "Epoch 3/3, Batch 1000/2500, Loss: 0.1486\n",
      "Epoch 3/3, Batch 1100/2500, Loss: 0.1486\n",
      "Epoch 3/3, Batch 1200/2500, Loss: 0.1486\n",
      "Epoch 3/3, Batch 1300/2500, Loss: 0.1469\n",
      "Epoch 3/3, Batch 1400/2500, Loss: 0.1450\n",
      "Epoch 3/3, Batch 1500/2500, Loss: 0.1472\n",
      "Epoch 3/3, Batch 1600/2500, Loss: 0.1486\n",
      "Epoch 3/3, Batch 1700/2500, Loss: 0.1477\n",
      "Epoch 3/3, Batch 1800/2500, Loss: 0.1477\n",
      "Epoch 3/3, Batch 1900/2500, Loss: 0.1477\n",
      "Epoch 3/3, Batch 2000/2500, Loss: 0.1481\n",
      "Epoch 3/3, Batch 2100/2500, Loss: 0.1490\n",
      "Epoch 3/3, Batch 2200/2500, Loss: 0.1491\n",
      "Epoch 3/3, Batch 2300/2500, Loss: 0.1483\n",
      "Epoch 3/3, Batch 2400/2500, Loss: 0.1486\n",
      "Epoch 3/3, Batch 2500/2500, Loss: 0.1488\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "class AlbertSentimentClassifier(nn.Module):\n",
    "    def __init__(self, albert_model):\n",
    "        super(AlbertSentimentClassifier, self).__init__()\n",
    "        self.albert = albert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.albert.config.hidden_size, 2)  # Binary classification: positive or negative\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        outputs = self.albert(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]  # Take the [CLS] token output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Instantiate the model\n",
    "model = AlbertSentimentClassifier(Model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "num_epochs = 3  # Example, you can adjust this\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (input_ids, token_type_ids, labels) in enumerate(train_iter):\n",
    "        input_ids, token_type_ids, labels = input_ids.to(device), token_type_ids.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_iter)}, Loss: {total_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f81621-58ed-44d4-8c00-36e08951a045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'albert_IMDB.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11288b25-c5c3-4db6-a8a9-ecaf2c4c6fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "class AlbertSentimentClassifier(nn.Module):\n",
    "    def __init__(self, albert_model):\n",
    "        super(AlbertSentimentClassifier, self).__init__()\n",
    "        self.albert = albert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.albert.config.hidden_size, 2)  # Binary classification: positive or negative\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        outputs = self.albert(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]  # Take the [CLS] token output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "device = try_all_gpus()\n",
    "Model = torch.load('albert_IMDB.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f185a1a-4efb-4abe-9077-af1564150176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9550\n",
      "Accuracy on test set: 0.9193\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_iter):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, token_type_ids, labels in test_iter:\n",
    "            input_ids, token_type_ids, labels = input_ids.to(device), token_type_ids.to(device), labels.to(device)\n",
    "\n",
    "            logits = model(input_ids, token_type_ids)\n",
    "            _, predictions = torch.max(logits, 1)\n",
    "\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(Model, test_iter_pos)\n",
    "evaluate_model(Model, test_iter_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d5824f-3994-4baf-b6a3-9a0f332b816b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation location:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1250 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "100%|██████████| 1250/1250 [01:06<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trigger tokens state：the accuracy 0.95448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1250 [00:00<?, ?it/s]/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "100%|██████████| 1250/1250 [03:04<00:00,  6.77it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.63it/s]\n",
      "100%|██████████| 1250/1250 [01:06<00:00, 18.66it/s]\n",
      "100%|██████████| 1250/1250 [01:06<00:00, 18.66it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.66it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:06<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1 rounds of attacking\n",
      "triggers: tensor([29269, 29269]) \n",
      "the accuracy :0.90680 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:04<00:00,  6.77it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.61it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.61it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.60it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.59it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.60it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.61it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2 rounds of attacking\n",
      "triggers: tensor([9148,    9]) \n",
      "the accuracy :0.87352 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:05<00:00,  6.75it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:06<00:00, 18.66it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.63it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.62it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.61it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3 rounds of attacking\n",
      "triggers: tensor([8554,    9]) \n",
      "the accuracy :0.69752 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 284/1250 [00:42<02:23,  6.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 167\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trigger_token[\u001b[38;5;241m0\u001b[39m], valid_acc  \u001b[38;5;66;03m# Return the final trigger token and the accuracy after the attack\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m#collection_attack(Model, test_iter_pos, 5, 10, trigger='<pad>', num_trigger_tokens=1)\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[43mcollection_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<pad>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trigger_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m#collection_attack(Model, test_iter_pos, 5, 10, trigger='<pad>', num_trigger_tokens=3)\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m#collection_attack(Model, test_iter_neg, 5, 10, trigger='<pad>', num_trigger_tokens=1)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m collection_attack(Model, test_iter_neg, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, trigger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m'\u001b[39m, num_trigger_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 115\u001b[0m, in \u001b[0;36mcollection_attack\u001b[0;34m(net, test_iter, num_candidates, num_epoch, trigger, num_trigger_tokens)\u001b[0m\n\u001b[1;32m    113\u001b[0m extracted_grads\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    114\u001b[0m hook \u001b[38;5;241m=\u001b[39m add_hook(net)\n\u001b[0;32m--> 115\u001b[0m \u001b[43mget_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger_token_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m hook\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m    117\u001b[0m average_grad \u001b[38;5;241m=\u001b[39m process_gradient(\u001b[38;5;28mlen\u001b[39m(test_iter), num_trigger_tokens)\n",
      "Cell \u001b[0;32mIn[4], line 72\u001b[0m, in \u001b[0;36mget_gradient\u001b[0;34m(net, test_iter, trigger_token_tensor)\u001b[0m\n\u001b[1;32m     70\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, y)\n\u001b[1;32m     71\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 72\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "### Trigger Token\n",
    "\n",
    "def init_trigger_tokens(trigger, num_trigger_tokens):\n",
    "    # Initialize trigger tokens, we use 'the' as initial trigger token\n",
    "    trigger_token_ids = [0] * num_trigger_tokens  # 1996 means 'the'\n",
    "    trigger_token_tensor = torch.tensor(trigger_token_ids)\n",
    "    return trigger_token_tensor\n",
    "\n",
    "\n",
    "def evaluate(net, test_iter, trigger_token_tensor):\n",
    "    # evaluate the accuracy of the model after concatenating the initial trigger token\n",
    "    net = net.to(device[0])\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    n = torch.tensor([0] * len(trigger_token_tensor))\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    n = n.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            a, b, y = batch\n",
    "            a = torch.cat((a[:, :position], m.repeat_interleave(a.shape[0], dim=0), a[:, position:]), dim=1)\n",
    "            b = torch.cat((b[:, :position], n.repeat_interleave(b.shape[0], dim=0), b[:, position:]), dim=1)\n",
    "            a = a.to(device[0])\n",
    "            b = b.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            # outputs = net(input_ids=a, token_type_ids=b)\n",
    "            # acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "            logits = net(input_ids = a, token_type_ids = b)\n",
    "            acc = (logits.argmax(dim=-1) == y).float().mean()\n",
    "            valid_accs.append(acc)\n",
    "    valid_acc = sum(valid_accs) / len(test_iter)\n",
    "    return valid_acc\n",
    "\n",
    "def extract_grad_hook(net, grad_in, grad_out):  # store the gradient in extracted_grads\n",
    "    extracted_grads.append(grad_out[0].mean(dim=0))\n",
    "\n",
    "\n",
    "def add_hook(net):\n",
    "    for module in net.modules():\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            hook = module.register_backward_hook(extract_grad_hook)\n",
    "            break\n",
    "    return hook\n",
    "\n",
    "\n",
    "def get_gradient(net, test_iter, trigger_token_tensor):  # Calculate the loss to get the gradient\n",
    "    net = net.to(device[0])\n",
    "    net.train()\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    n = torch.tensor([0] * len(trigger_token_tensor))\n",
    "    n = n.unsqueeze(0)\n",
    "    optimizer = torch.optim.AdamW(net.parameters())\n",
    "    for batch in tqdm(test_iter):\n",
    "        a, b, y = batch\n",
    "        a = torch.cat((a[:, :position], m.repeat_interleave(a.shape[0], dim=0), a[:, position:]), dim=1)\n",
    "        b = torch.cat((b[:, :position], n.repeat_interleave(b.shape[0], dim=0), b[:, position:]), dim=1)\n",
    "        a = a.to(device[0])\n",
    "        b = b.to(device[0])\n",
    "        y = y.to(device[0])\n",
    "        '''\n",
    "        outputs = net(input_ids=a, token_type_ids=b)\n",
    "        l = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        '''\n",
    "        logits = net(input_ids = a, token_type_ids = b)\n",
    "        loss = criterion(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "def process_gradient(length, num_trigger_tokens):  # Process the gradient to get the average gradient\n",
    "    extracted_grads_copy = extracted_grads\n",
    "    extracted_grads_copy[0] = extracted_grads_copy[0]\n",
    "    temp = extracted_grads_copy[0]\n",
    "    temp = temp.unsqueeze(0)\n",
    "    for i in range(1, length - 1):\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i]\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i].unsqueeze(0)\n",
    "        temp = torch.cat((temp, extracted_grads_copy[i]), dim=0)\n",
    "    average_grad = temp.mean(dim=0)[position:position + num_trigger_tokens]\n",
    "    return average_grad\n",
    "\n",
    "\n",
    "def hotflip_attack(averaged_grad, embedding_matrix,\n",
    "                   num_candidates=1, increase_loss=False):\n",
    "    averaged_grad = averaged_grad.cpu()\n",
    "    embedding_matrix = embedding_matrix.cpu()\n",
    "    averaged_grad = averaged_grad.unsqueeze(0)\n",
    "    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n",
    "                                                 (averaged_grad, embedding_matrix))\n",
    "    if not increase_loss:\n",
    "        gradient_dot_embedding_matrix *= -1\n",
    "        # lower versus increase the class probability.\n",
    "    if num_candidates > 1:  # get top k options\n",
    "        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n",
    "        return best_k_ids.detach().cpu().numpy()[0]  # Return candidates\n",
    "    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n",
    "    return best_at_each_step[0].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def collection_attack(net, test_iter, num_candidates, num_epoch, trigger='the',  # Summarize each function\n",
    "                      num_trigger_tokens=3):\n",
    "    trigger_token_tensor = init_trigger_tokens(trigger, num_trigger_tokens)\n",
    "    print(f'Concatenation location:{position}')\n",
    "    valid_acc = evaluate(net, test_iter, trigger_token_tensor)\n",
    "    print(f'Initial trigger tokens state：the accuracy {valid_acc:.5f}')\n",
    "    embedding_weight = get_embedding_weight(net)\n",
    "    for i in range(num_epoch):\n",
    "        extracted_grads.clear()\n",
    "        hook = add_hook(net)\n",
    "        get_gradient(net, test_iter, trigger_token_tensor)\n",
    "        hook.remove()\n",
    "        average_grad = process_gradient(len(test_iter), num_trigger_tokens)\n",
    "        hot_token = hotflip_attack(average_grad, embedding_weight, num_candidates, increase_loss=True)\n",
    "        hot_token_tensor = torch.from_numpy(hot_token)\n",
    "        trigger_token_tensor, valid_acc = select_best_candid(net, test_iter, hot_token_tensor, trigger_token_tensor,\n",
    "                                                             valid_acc)\n",
    "        print(f'after {i + 1} rounds of attacking\\ntriggers: {trigger_token_tensor} \\nthe accuracy :{valid_acc:.5f} ')\n",
    "    return trigger_token_tensor, valid_acc  # Return the final trigger tokens (trigger length) and the accuracy after the attack\n",
    "\n",
    "\n",
    "def get_embedding_weight(net):\n",
    "    for module in net.modules():\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            weight = module.weight\n",
    "            break\n",
    "    return weight\n",
    "\n",
    "\n",
    "def select_best_candid(net, test_iter, candid_trigger, trigger_token, valid_acc):\n",
    "    # Concatenate each candidate to each input to determine the final trigger token\n",
    "    n = torch.tensor([0] * len(trigger_token))\n",
    "    n = n.unsqueeze(0)\n",
    "    trigger_token = trigger_token.unsqueeze(0)\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    for i in range(candid_trigger.shape[0]):\n",
    "        trigger_token_temp = deepcopy(trigger_token)\n",
    "        for j in range(candid_trigger.shape[1]):\n",
    "            trigger_token_temp[0, i] = candid_trigger[i, j]\n",
    "            valid_accs = []\n",
    "            for batch in tqdm(test_iter):\n",
    "                a, b, y = batch\n",
    "                a = torch.cat((a[:, :position], trigger_token_temp.repeat_interleave(a.shape[0], dim=0),\n",
    "                               a[:, position:]), dim=1)\n",
    "                b = torch.cat((b[:, :position], n.repeat_interleave(b.shape[0], dim=0),\n",
    "                               b[:, position:]), dim=1)\n",
    "                a = a.to(device[0])\n",
    "                b = b.to(device[0])\n",
    "                y = y.to(device[0])\n",
    "                #outputs = net(input_ids=a, token_type_ids=b)\n",
    "                #acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "                logits = net(input_ids = a, token_type_ids = b)\n",
    "                acc = (logits.argmax(dim=-1) == y).float().mean()\n",
    "                valid_accs.append(acc)\n",
    "            temp = sum(valid_accs) / len(test_iter)\n",
    "            if temp < valid_acc:\n",
    "                valid_acc = temp\n",
    "                trigger_token[0, i] = candid_trigger[i, j]\n",
    "    return trigger_token[0], valid_acc  # Return the final trigger token and the accuracy after the attack\n",
    "\n",
    "#collection_attack(Model, test_iter_pos, 5, 10, trigger='<pad>', num_trigger_tokens=1)\n",
    "collection_attack(Model, test_iter_pos, 5, 5, trigger='<pad>', num_trigger_tokens=2)\n",
    "#collection_attack(Model, test_iter_pos, 5, 10, trigger='<pad>', num_trigger_tokens=3)\n",
    "\n",
    "#collection_attack(Model, test_iter_neg, 5, 10, trigger='<pad>', num_trigger_tokens=1)\n",
    "collection_attack(Model, test_iter_neg, 5, 5, trigger='<pad>', num_trigger_tokens=2)\n",
    "#collection_attack(Model, test_iter_neg, 5, 10, trigger='<pad>', num_trigger_tokens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ccf18c-c91e-4786-8498-d4f59ecc4ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation location:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:06<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trigger tokens state：the accuracy 0.91936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:04<00:00,  6.77it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.62it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.62it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.62it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.62it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.53it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.55it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.55it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.57it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.56it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1 rounds of attacking\n",
      "triggers: tensor([29376, 27135]) \n",
      "the accuracy :0.91776 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:05<00:00,  6.75it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:06<00:00, 18.66it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.63it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.63it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.63it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2 rounds of attacking\n",
      "triggers: tensor([29376, 27135]) \n",
      "the accuracy :0.91776 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:04<00:00,  6.76it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.62it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.63it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.65it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n",
      "100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3 rounds of attacking\n",
      "triggers: tensor([29376, 27135]) \n",
      "the accuracy :0.91776 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 86/1250 [00:12<02:53,  6.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcollection_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter_neg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<pad>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trigger_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 115\u001b[0m, in \u001b[0;36mcollection_attack\u001b[0;34m(net, test_iter, num_candidates, num_epoch, trigger, num_trigger_tokens)\u001b[0m\n\u001b[1;32m    113\u001b[0m extracted_grads\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    114\u001b[0m hook \u001b[38;5;241m=\u001b[39m add_hook(net)\n\u001b[0;32m--> 115\u001b[0m \u001b[43mget_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger_token_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m hook\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m    117\u001b[0m average_grad \u001b[38;5;241m=\u001b[39m process_gradient(\u001b[38;5;28mlen\u001b[39m(test_iter), num_trigger_tokens)\n",
      "Cell \u001b[0;32mIn[4], line 72\u001b[0m, in \u001b[0;36mget_gradient\u001b[0;34m(net, test_iter, trigger_token_tensor)\u001b[0m\n\u001b[1;32m     70\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, y)\n\u001b[1;32m     71\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 72\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "collection_attack(Model, test_iter_neg, 5, 5, trigger='<pad>', num_trigger_tokens=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
