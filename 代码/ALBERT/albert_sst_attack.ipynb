{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd18c096-e1fc-4b20-8891-56a9c42cd9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import random\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "\n",
    "global extracted_grads\n",
    "\n",
    "extracted_grads = []\n",
    "position = 1  # concatenation position\n",
    "# the concatenation position of the BERT model is after the [CLS] token\n",
    "# Random Concatenation Mode\n",
    "# position = random.randint(1,500)\n",
    "\n",
    "tokenize = AlbertTokenizer.from_pretrained(\"/root/albert\")\n",
    "Model = AlbertModel.from_pretrained(\"/root/albert\")\n",
    "\n",
    "\n",
    "# Load model related information\n",
    "\n",
    "# Print the number of Total Parameters\n",
    "# total = [param.nelement() for param in Model.parameters()]\n",
    "# print(f'total parameters:{format(sum(total))}\\n each layer parameters{total} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c4223a-46ce-4ea5-a97e-5cd39b38bb61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: This is a good example.\n",
      "Adversarial sentence: This live a in_force object_lesson .\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)\n",
    "\n",
    "def textfooler(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    \n",
    "    for i, (word, tag) in enumerate(tagged_tokens):\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag is None:\n",
    "            continue\n",
    "        \n",
    "        synonyms = generate_synonyms(word)\n",
    "        if len(synonyms) > 0:\n",
    "            # Choose a random synonym as replacement\n",
    "            new_word = synonyms[0]\n",
    "            tokens[i] = new_word\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Example usage\n",
    "original_sentence = \"This is a good example.\"\n",
    "adversarial_sentence = textfooler(original_sentence)\n",
    "print(\"Original sentence:\", original_sentence)\n",
    "print(\"Adversarial sentence:\", adversarial_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ab33a0-2940-467e-b60c-0dc414ac7adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "               for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "# Define the model architecture\n",
    "class AlbertSentimentClassifier(nn.Module):\n",
    "    def __init__(self, albert_model):\n",
    "        super(AlbertSentimentClassifier, self).__init__()\n",
    "        self.albert = albert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.albert.config.hidden_size, 2)  # Binary classification: positive or negative\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        outputs = self.albert(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]  # Take the [CLS] token output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "device = try_all_gpus()\n",
    "Model = torch.load('albert_SST.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d46310-303d-4dd9-afff-7f9985bd6e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_iter):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, token_type_ids, labels in test_iter:\n",
    "            input_ids, token_type_ids, labels = input_ids.to(device), token_type_ids.to(device), labels.to(device)\n",
    "\n",
    "            logits = model(input_ids, token_type_ids)\n",
    "            _, predictions = torch.max(logits, 1)\n",
    "\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Accuracy on test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5073461d-a7cb-438a-8b8f-6219110ec6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "SST-2 Data\n",
    "'''\n",
    "\n",
    "\n",
    "### Load data\n",
    "\n",
    "\n",
    "def read_sst_test_data1(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '1':  # pos\n",
    "                review = textfooler(line[1])\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "def read_sst_test_data2(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '1':  # pos\n",
    "                review = textfooler(line[1])\n",
    "                review = \"mistake somehow drugged \" + review\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def load_sst_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Constructs a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "def load_sst_data1(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data1(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter\n",
    "\n",
    "def load_sst_data2(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data2(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8c4adea-6586-49bd-9b3f-2950e23d6e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_iter1 = load_sst_data1(10)\n",
    "test_iter2 = load_sst_data2(10)\n",
    "\n",
    "#train_iter, test_iter = load_sst_data(10)\n",
    "# Data preprocessing and loading\n",
    "print(\"reading data finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4df935-9748-4747-af81-328fba07a3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5809\n",
      "Accuracy on test set: 0.0275\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Model, test_iter1)\n",
    "evaluate_model(Model, test_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bf312f9-cd44-4e49-a9dd-3f46342899b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "SST-2 Data\n",
    "'''\n",
    "\n",
    "\n",
    "### Load data\n",
    "\n",
    "\n",
    "def read_sst_test_data1(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '0':  # neg\n",
    "                review = textfooler(line[1])\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "def read_sst_test_data2(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '0':  # neg\n",
    "                review = textfooler(line[1])\n",
    "                review = \"refreshing filled rippling \" + review\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def load_sst_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Constructs a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "def load_sst_data1(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data1(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter\n",
    "\n",
    "def load_sst_data2(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data2(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16bb44ca-0c1f-4c82-9549-100855cd1ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_iter1 = load_sst_data1(10)\n",
    "test_iter2 = load_sst_data2(10)\n",
    "\n",
    "#train_iter, test_iter = load_sst_data(10)\n",
    "# Data preprocessing and loading\n",
    "print(\"reading data finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22db519e-2def-4676-b7b2-b62b5fd4ec71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8805\n",
      "Accuracy on test set: 0.0285\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Model, test_iter1)\n",
    "evaluate_model(Model, test_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70358e-70fa-4943-aa33-7e86962a7c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17b3a4-0cfc-4fc6-b7c3-21a350cd8b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5138765-c9e7-4907-bb8a-81badc88051e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "SST-2 Data\n",
    "'''\n",
    "\n",
    "\n",
    "### Load data\n",
    "\n",
    "\n",
    "def read_sst_test_data1(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '1':  # pos\n",
    "                review = textfooler(line[1])\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "def read_sst_test_data2(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '1':  # pos\n",
    "                review = textfooler(line[1])\n",
    "                review = \"stupid angrily whether \" + review\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def load_sst_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Constructs a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "def load_sst_data1(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data1(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter\n",
    "\n",
    "def load_sst_data2(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data2(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a54761-c21e-44c0-9ef7-e67f3e20a682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_iter1 = load_sst_data1(10)\n",
    "test_iter2 = load_sst_data2(10)\n",
    "\n",
    "#train_iter, test_iter = load_sst_data(10)\n",
    "# Data preprocessing and loading\n",
    "print(\"reading data finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e4601bf-29ef-4775-9017-460c6201fb05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5776\n",
      "Accuracy on test set: 0.0495\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Model, test_iter1)\n",
    "evaluate_model(Model, test_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5f7b6d-3496-4f9b-bebe-492b56cf814e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data finished\n",
      "\n",
      "Accuracy on test set: 0.8454\n",
      "Accuracy on test set: 0.0428\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SST-2 Data\n",
    "'''\n",
    "\n",
    "\n",
    "### Load data\n",
    "\n",
    "\n",
    "def read_sst_test_data1(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '0':  # pos\n",
    "                review = textfooler(line[1])\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "def read_sst_test_data2(data_dir):\n",
    "    data, labels = [], []\n",
    "    csv.register_dialect('my', delimiter='\\t', quoting=csv.QUOTE_ALL)\n",
    "    with open(data_dir) as tsvfile:\n",
    "        file_list = csv.reader(tsvfile, \"my\")\n",
    "        first = True\n",
    "        for line in file_list:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            if line[0] == '0':  # pos\n",
    "                review = textfooler(line[1])\n",
    "                review = \"smoothly beautifully irresistible \" + review\n",
    "                data.append(review)\n",
    "                labels.append(int(line[0]))\n",
    "    csv.unregister_dialect('my')\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def load_sst_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Constructs a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "def load_sst_data1(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data1(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter\n",
    "\n",
    "def load_sst_data2(batch_size, num_steps=500):\n",
    "    test_data = read_sst_test_data2(\"SST-2/test.tsv\")\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=num_steps)\n",
    "    test_iter = load_sst_array(\n",
    "        (test_encoding['input_ids'], test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "        1,\n",
    "        is_train=False)\n",
    "    return test_iter\n",
    "\n",
    "test_iter1 = load_sst_data1(10)\n",
    "test_iter2 = load_sst_data2(10)\n",
    "\n",
    "#train_iter, test_iter = load_sst_data(10)\n",
    "# Data preprocessing and loading\n",
    "print(\"reading data finished\\n\")\n",
    "\n",
    "evaluate_model(Model, test_iter1)\n",
    "evaluate_model(Model, test_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21157cf-344c-40df-a611-edf7f38e59f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b9ce8-e21d-4581-9109-01f94f6cf29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
